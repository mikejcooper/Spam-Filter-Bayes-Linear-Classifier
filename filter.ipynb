{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment : Spam Filter\n",
    "## Description\n",
    "This assignment is near-final modulo some small adjustments (6 Nov '16)\n",
    "In this assignment, you will discover that in many practical machine learning problems implementing the learning algorithm is often only a small part of the overall system. Thus to get a high mark for this assignment you need to implement any of the more advanced classification techniques or clever pre-processing methods. You will find plenty of them on the internet. If you do not know where to look for them, ask Google ;-).\n",
    "\n",
    "Here your task is to build the standard (i.e. multinomial) Naive Bayes text classifier described during the lectures. You should test your program using the automatic marking software (described below), so it is critically important that it follows the specifications in detail.\n",
    "\n",
    "You will train your classifier on real-world e-mails, which you can download from here. Each training e-mail is stored in a separate file. The names of spam training e-mails start with spam, while the names of ham e-mails start with ham.\n",
    "\n",
    "## Marking criteria\n",
    "\n",
    "Part 1 (40%):\n",
    "    - Your program classifies the testing set with an accuracy significantly higher than random within 30 minutes\n",
    "    - Use very simple data preprocessing so that the emails can be read into the Naive Bayes (remove everything else other than words from emails)\n",
    "    - Write simple Naive Bayes multinomial classifier or use an implementation from a library of your choice\n",
    "    - Classify the data\n",
    "    - Report your results with a metric (e.g. accuracy) and method (e.g. cross validation) of your choice\n",
    "    - Choose a baseline and compare your classifier against it\n",
    "\n",
    "Part 2 (30%):\n",
    "    - Use some smart feature processing techniques to improve the classification results\n",
    "    - Compare the classification results with and without these techniques\n",
    "    - Analyse how the classification results depend on the parameters (if available) of chosen techniques\n",
    "    - Compare (statistically) your results against any other algorithm of your choice (use can use any library); compare and contrast results, ensure fair comparison\n",
    "\n",
    "Part 3 (30%):\n",
    "    - Calibration (15%): calibrate Naive Bayes probabilities, such that they result in low mean squared error\n",
    "    - Naive Bayes extension (15%): modify the algorithm in some interesting way (e.g. weighted Naive Bayes)\n",
    "    \n",
    "\n",
    "** Convert from .ipynb to .py : ** $ ipython nbconvert --to python filter.ipynb\n",
    "\n",
    "** BeautifulSoup: ** $ pip install beautifulsoup4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import email\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "import os, re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 1 Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are receiving this email because you signed up to receive one of our free reports if you would prefer not to receive messages of this type please unsubscribe by following the instructions at the bottom of this message dear investor thank you again for requesting our free special report the one stock that keeps wall street buzzing we began the motley fool in with the idea that investors like you deserved better better than wall streets alltoooften biased research better than analysts who speak in secret codes allowing them to hedge or spin any recommendation and better than what passes for full financial disclosure in big business today given a level playing field we believe that regular folks like us and you can do quite well in the stock market why put trust in conflicted information from others when you could count on your own abilities and potentially blow the pros away more than two million people visit our foolcom web site each month we spend a great deal of time at foolcom instructing people how to invest but not so much about where to invest and thats why we created the motley fool stock advisor you are cordially invited to join us as a charter subscriber to motley fool stock advisor as we focus on the great companies of the us stock market in the same honest noholdsbarred style that has made foolcom so popular with investors well bring you our best stock recommendations and other financial insights to help you achieve your financial dreams as a charter subscriber youll get the motley fool stock advisor newsletter delivered to your home each month a personal communication from us david tom gardner well tell you exactly why we believe a stock is poised for significant growth and give you all the facts to back that analysis up youll get the good the bad and the ugly on every recommendation we make so you can make each investing decision with great confidence of course theres more to our motley fool stock advisor than our monthly newsletter youll also receive our monthly betweenissue email fool flash to help you take full advantage of breaking opportunities and you can log on anytime at the motley fool stock advisor subscriberonly web site featuring current back newsletter issuesfull updates on our selected stocksq aand more best of all you can try our motley fool stock advisor entirely riskfree the motley fool community has always been based upon trust and value principles we intend to continue here so we want to give you plenty of time to decide if our motley fool stock advisor is a valuable investing tool for you you can try our motley fool stock advisor for six full months riskfree if we dont prove its worth to you it doesnt cost you a dime and you have our word on that so join us now its going to be fun its going to be exciting and its going to be an enriching experience you wont want to miss to join us riskfree as a charter subscriber to david tom gardners motley fool stock advisor simply click here now foolishly yours david tom gardner the motley fool ps click here to check out the free bonuses you get when you subscribe special reports videos online seminars all yours to enjoy and keep even if you cancel your trial subscription to our motley fool stock advisor remember you have six full months to evaluate our new service dont like what you see dont make the profits you expectthen it doesnt cost you a dime so this invitation is truly riskfree click here now how to unsubscribe we hope this email message is of value to you if however you do not wish to receive any of our future messages please unsubscribe by going to the following web address note if you unsubscribe by replying to this message please use unsubscribe or remove in the subject line thu jul\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Removes header from email if present\n",
    "def get_body(msg):\n",
    "    if msg.is_multipart():\n",
    "        for payload in msg.get_payload():\n",
    "            # if payload.is_multipart(): ...\n",
    "            return payload.get_payload()\n",
    "    else:\n",
    "        return msg.get_payload()\n",
    "    \n",
    "    \n",
    "# Returns text containing only words (lowercase)\n",
    "def remove_extras(text):\n",
    "    brackets = \"\\([^)]*\\)\"\n",
    "    email_address = \"([\\w.-]+)@([\\w.-]+)\"\n",
    "    web_address = \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    numbers = \"\\d+\"\n",
    "    alphanumeric = \"([^\\s\\w]|_)+\"\n",
    "    whitespace = \"\\s+\"\n",
    "    stop_words = '\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*'\n",
    "\n",
    "    text = re.sub(email_address, '', text)\n",
    "    text = re.sub(web_address, '', text)\n",
    "    text = re.sub(numbers, '', text)\n",
    "    text = re.sub(alphanumeric, '', text)\n",
    "    text = re.sub(whitespace, ' ', text).strip()\n",
    "    text = text.lower() # Lowercase\n",
    "    return text\n",
    "\n",
    "def simple_html_filter(html_doc):\n",
    "\n",
    "    soup = BeautifulSoup(str(html_doc), \"html.parser\")\n",
    "\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # rip it out\n",
    "\n",
    "    text = soup.get_text()\n",
    "    # break into lines and remove leading and trailing space on each\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    # break multi-headlines into a line each\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    # drop blank lines\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def filter_stop_words(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    return text\n",
    "    \n",
    "    \n",
    "def filter_part1(email): \n",
    "    message = get_body(email)\n",
    "    message = simple_html_filter(message)\n",
    "    message = remove_extras(message)\n",
    "    message = filter_stop_words(message)\n",
    "    return message\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "\n",
    "# Example\n",
    "\n",
    "with open('training_data/ham000.txt') as f:\n",
    "    text_test = f.read()\n",
    "\n",
    "msg = email.message_from_string(text_test)\n",
    "\n",
    "print(filter_part1(msg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 2 Filtering ** - ignore for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\"David&TomGardner@fooladvisor.com\"<Subscriber@fooladvisor.com>'"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from email.header import decode_header\n",
    "def getheader(header_text, default=\"ascii\"):\n",
    "    \"\"\"Decode the specified header\"\"\"\n",
    "\n",
    "    headers = decode_header(header_text)\n",
    "    header_sections = [unicode(text, charset or default)\n",
    "                       for text, charset in headers]\n",
    "    return u\"\".join(header_sections)\n",
    "\n",
    "\n",
    "getheader(msg[\"from\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in all documents and convert to a bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "data = []\n",
    "training_labels = []\n",
    "training_label_names = ['ham', 'spam']\n",
    "        \n",
    "# ham\n",
    "for filename in glob.glob('training_data/ham*.txt'):\n",
    "    f = open(filename, 'r')\n",
    "    data.append(f.read())\n",
    "    training_labels.append(0)\n",
    "\n",
    "# spam    \n",
    "for filename in glob.glob('training_data/spam*.txt'):\n",
    "    f = open(filename, 'r')\n",
    "    data.append(f.read())\n",
    "    training_labels.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "class PreProcessor(object):\n",
    "\n",
    "    def transform(self, X):\n",
    "        out = []\n",
    "        isRiskFree = False\n",
    "        for item in X:\n",
    "            data = filter_part1(email.message_from_string(item))\n",
    "            out.append(data)\n",
    "        return out\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "text_clf = Pipeline([('preprocess', PreProcessor()),\n",
    "                     ('vect', CountVectorizer(decode_error='ignore')),\n",
    "#                      ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we can actually use a naive Bayes classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# we're using multinomial because it's most relevant for word counts\n",
    "text_clf = text_clf.fit(data, training_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done :) Now we can test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 0 0 0 0]\n",
      "'ham' => ham\n",
      "'ham' => ham\n",
      "'spam' => spam\n",
      "'ham' => ham\n",
      "'spam' => ham\n",
      "'spam' => spam\n",
      "'ham' => ham\n",
      "'ham' => ham\n",
      "'ham' => ham\n",
      "'ham' => ham\n",
      "9 correctly classified out of 10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def pickTestData(count=1):\n",
    "    labelsFile = open('testdata.label', 'r')\n",
    "    labeling = labelsFile.readlines()\n",
    "    random.shuffle(labeling)\n",
    "    sample = labeling[0:count]\n",
    "#     return [('new risk want addresses', 2)]\n",
    "    return [(open('test_data/'+row.split()[1], 'r').read(), 1-int(row.split()[0])) for row in sample]\n",
    "\n",
    "test_data = pickTestData(10)\n",
    "\n",
    "docs_new = [i[0] for i in test_data]\n",
    "\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = text_clf.predict(docs_new)\n",
    "\n",
    "tot_correct = 0\n",
    "\n",
    "print(predicted)\n",
    "\n",
    "for original_data, category in zip(test_data, predicted):\n",
    "    print('%r => %s' % (training_label_names[original_data[1]], training_label_names[category]))\n",
    "    if original_data[1] == category:\n",
    "        tot_correct += 1\n",
    "\n",
    "print('%d correctly classified out of %d' % (tot_correct, len(test_data)))\n",
    "\n",
    "# np.mean(predicted == training_labels)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
